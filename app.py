import numpy as np
import matplotlib.pyplot as plt
import streamlit as st


# -----------------------------
# Streamlit temel ayar
# -----------------------------
st.set_page_config(page_title="Gradient Descent Lab", page_icon="â¬‡ï¸")

st.title("â¬‡ï¸ Gradient Descent SimÃ¼latÃ¶rÃ¼ â€“ YokuÅŸtan AÅŸaÄŸÄ± Ä°nen Top")
st.write(
    """
Bu laboratuvarda tek deÄŸiÅŸkenli bir fonksiyon Ã¼zerinde
**gradient descent (eÄŸim azalÄ±ÅŸÄ±)** yÃ¶ntemini inceleyeceksin.

- Bir fonksiyon seÃ§ (parabol veya Ã§ukurlu fonksiyon)  
- BaÅŸlangÄ±Ã§ noktasÄ±nÄ± (**xâ‚€**) belirle  
- Ã–ÄŸrenme oranÄ±nÄ± (**Î·**) ve adÄ±m sayÄ±sÄ±nÄ± seÃ§  
- Topun her adÄ±mda vadinin tabanÄ±na nasÄ±l yaklaÅŸtÄ±ÄŸÄ±nÄ± grafikte izle
"""
)

st.markdown("---")


# -----------------------------
# Fonksiyon seÃ§imi
# -----------------------------
st.subheader("1ï¸âƒ£ Fonksiyonu SeÃ§")

func_name = st.radio(
    "Fonksiyon:",
    [
        "Basit Parabol: f(x) = xÂ²",
        "Ã‡ukurlu Fonksiyon: f(x) = xâ´/4 âˆ’ xÂ²/2",
    ],
)


def f(x: np.ndarray, name: str) -> np.ndarray:
    """SeÃ§ilen fonksiyonun deÄŸeri."""
    if name == "Basit Parabol: f(x) = xÂ²":
        return x**2
    elif name == "Ã‡ukurlu Fonksiyon: f(x) = xâ´/4 âˆ’ xÂ²/2":
        return (x**4) / 4 - (x**2) / 2
    else:
        return x**2


def f_prime(x: np.ndarray, name: str) -> np.ndarray:
    """SeÃ§ilen fonksiyonun tÃ¼revi."""
    if name == "Basit Parabol: f(x) = xÂ²":
        return 2 * x
    elif name == "Ã‡ukurlu Fonksiyon: f(x) = xâ´/4 âˆ’ xÂ²/2":
        # f'(x) = xÂ³ - x
        return x**3 - x
    else:
        return 2 * x


# GrafiÄŸi Ã§izmek iÃ§in x aralÄ±ÄŸÄ±
if func_name == "Basit Parabol: f(x) = xÂ²":
    x_min, x_max = -5.0, 5.0
else:
    x_min, x_max = -3.0, 3.0

x_plot = np.linspace(x_min, x_max, 400)
y_plot = f(x_plot, func_name)


# -----------------------------
# Gradient descent parametreleri
# -----------------------------
st.subheader("2ï¸âƒ£ Gradient Descent Parametrelerini Ayarla")

col_params1, col_params2 = st.columns(2)
with col_params1:
    x0 = st.slider(
        "BaÅŸlangÄ±Ã§ noktasÄ± xâ‚€",
        min_value=float(x_min),
        max_value=float(x_max),
        value=2.5 if func_name == "Basit Parabol: f(x) = xÂ²" else 2.0,
        step=0.1,
    )

with col_params2:
    eta = st.slider(
        "Ã–ÄŸrenme oranÄ± (Î·)",
        min_value=0.01,
        max_value=0.5,
        value=0.1,
        step=0.01,
        help="AdÄ±m boyu. Ã‡ok kÃ¼Ã§Ã¼k olursa yavaÅŸ, Ã§ok bÃ¼yÃ¼k olursa zÄ±playarak sapÄ±tabilir.",
    )

n_steps = st.slider(
    "AdÄ±m sayÄ±sÄ±",
    min_value=1,
    max_value=50,
    value=15,
    step=1,
)

st.write(
    f"BaÅŸlangÄ±Ã§: **xâ‚€ = {x0:.2f}**, Ã¶ÄŸrenme oranÄ±: **Î· = {eta:.2f}**, adÄ±m sayÄ±sÄ±: **{n_steps}**"
)

st.markdown(
    """
Gradient descent adÄ±m formÃ¼lÃ¼:

\\[
x_{k+1} = x_k - \\eta \\, f'(x_k)
\\]

Burada \\(f'(x_k)\\) fonksiyonun o noktadaki eÄŸimidir (tÃ¼rev).
"""
)


# -----------------------------
# Gradient descent adÄ±mlarÄ±nÄ± hesapla
# -----------------------------
xs = [x0]
ys = [f(np.array([x0]), func_name)[0]]

x_curr = x0
for _ in range(n_steps):
    grad = f_prime(np.array([x_curr]), func_name)[0]
    x_next = x_curr - eta * grad
    xs.append(x_next)
    ys.append(f(np.array([x_next]), func_name)[0])
    x_curr = x_next

xs = np.array(xs)
ys = np.array(ys)


# -----------------------------
# GÃ¶rselleÅŸtirme
# -----------------------------
st.markdown("---")
st.subheader("3ï¸âƒ£ Grafikte Gradient Descent AdÄ±mlarÄ±nÄ± Ä°ncele")

fig, ax = plt.subplots(figsize=(7, 5))

# Fonksiyon eÄŸrisi
ax.plot(x_plot, y_plot, label="f(x)")

# AdÄ±m noktalarÄ±
ax.scatter(xs, ys, label="AdÄ±mlar (x_k)", zorder=3)
ax.plot(xs, ys, linestyle="--", alpha=0.7)

# Ä°lk ve son noktayÄ± etiketle
ax.scatter(xs[0], ys[0], s=60)
ax.text(xs[0], ys[0], "  BaÅŸlangÄ±Ã§", va="bottom")

ax.scatter(xs[-1], ys[-1], s=60)
ax.text(xs[-1], ys[-1], "  Son", va="bottom")

ax.set_xlabel("x")
ax.set_ylabel("f(x)")
ax.set_title("Gradient Descent Yolu")
ax.grid(True, linestyle="--", linewidth=0.5, alpha=0.5)
ax.legend()

st.pyplot(fig)


# -----------------------------
# AdÄ±m tablosu
# -----------------------------
st.subheader("4ï¸âƒ£ AdÄ±m AdÄ±m SayÄ±sal SonuÃ§lar")

import pandas as pd  # Streamlit iÃ§in tablo

step_indices = np.arange(len(xs))
grads = f_prime(xs, func_name)
df_steps = pd.DataFrame(
    {
        "k (adÄ±m)": step_indices,
        "x_k": xs,
        "f(x_k)": ys,
        "f'(x_k)": grads,
    }
)

st.dataframe(df_steps.style.format({"x_k": "{:.4f}", "f(x_k)": "{:.4f}", "f'(x_k)": "{:.4f}"}))


# -----------------------------
# AÃ§Ä±klama / Ã–ÄŸretmen kutusu
# -----------------------------
st.markdown("---")
st.info(
    "Gradient descent, fonksiyonun tÃ¼revine bakarak her adÄ±mda "
    "deÄŸerimizi en hÄ±zlÄ± azalÄ±ÅŸ yÃ¶nÃ¼nde gÃ¼ncelleyen basit ama gÃ¼Ã§lÃ¼ bir optimizasyon yÃ¶ntemidir. "
    "Yeterince kÃ¼Ã§Ã¼k bir Ã¶ÄŸrenme oranÄ± ile, uygun baÅŸlangÄ±Ã§ noktalarÄ±ndan minimuma doÄŸru yaklaÅŸÄ±rÄ±z."
)

with st.expander("ğŸ‘©â€ğŸ« Ã–ÄŸretmen Kutusu â€“ 1D Gradient Descent Sezgisi"):
    st.write(
        r"""
Tek deÄŸiÅŸkenli bir fonksiyon iÃ§in gradient descent adÄ±mÄ±:

\\[
x_{k+1} = x_k - \eta \, f'(x_k)
\\]

- EÄŸer \\(f'(x_k) > 0\\) ise, fonksiyon saÄŸa doÄŸru **yÃ¼kseliyor** demektir â†’ sola gitmek isteriz.  
  Bu nedenle \\(- \eta f'(x_k)\\) negatiftir â†’ \\(x_{k+1} < x_k\\).
- EÄŸer \\(f'(x_k) < 0\\) ise, fonksiyon sola doÄŸru **yÃ¼kseliyor** demektir â†’ saÄŸa gitmek isteriz.  
  Bu nedenle \\(- \eta f'(x_k)\\) pozitiftir â†’ \\(x_{k+1} > x_k\\).

Ã–ÄŸrenme oranÄ± \\(\eta\\):

- Ã‡ok kÃ¼Ã§Ã¼k â†’ yavaÅŸ ilerleme, ama genelde daha kararlÄ±.  
- Ã‡ok bÃ¼yÃ¼k â†’ minimumu atlayÄ±p saÄŸaâ€“sola zÄ±playabilir, bazen diverge olabilir.

Bu labda Ã¶ÄŸrenciler:

1. FarklÄ± \\(x_0\\) ve \\(\eta\\) seÃ§imlerinin yola etkisini gÃ¶rsel olarak inceler,  
2. AynÄ± fonksiyonun farklÄ± baÅŸlangÄ±Ã§lardan nasÄ±l farklÄ± yollarla ama benzer minima'lara gittiÄŸini gÃ¶zlemler.
"""
    )

st.caption(
    "Bu modÃ¼l, lise sonu / Ã¼niversite baÅŸÄ± dÃ¼zeyinde tÃ¼rev ve optimizasyon kavramlarÄ±na "
    "sezgisel bir giriÅŸ saÄŸlamak iÃ§in tasarlanmÄ±ÅŸtÄ±r."
)
